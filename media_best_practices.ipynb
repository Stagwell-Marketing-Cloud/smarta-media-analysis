{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import spacy\n",
    "\n",
    "from src.nlp.patterns.day_in_my_life import DAY_IN_MY_LIFE_PATTERNS\n",
    "from src.nlp.patterns.dupe import DUPE_PATTERNS\n",
    "from src.nlp.patterns.get_ready_with_me import GRWM_PATTERNS\n",
    "from src.nlp.patterns.point_of_view import POINT_OF_VIEW_PATTERNS\n",
    "from src.nlp.patterns.restocking import RESTOCKING_PATTERNS\n",
    "from src.nlp.patterns.unboxing import UNBOXING_PATTERNS\n",
    "from src.nlp.text_utils.text_contains_word import detect_patterns, ellipsis\n",
    "from src.nlp.patterns.call_to_action import CTA_PATTERNS\n",
    "from src.nlp.patterns.hack import HACK_PATTERNS\n",
    "from src.nlp.patterns.behind_the_scenes import BTS_PATTERNS\n",
    "from src.nlp.patterns.brand_matcher import ALL_BRAND_MATCHING_PHRASES\n",
    "from src.nlp.patterns.everyday_taks import TIPS_PATTERNS\n",
    "from src.nlp.text_utils.text_counter import count_two_words, paid_partnership, findall_counter\n",
    "from src.nlp.text_utils.text_emoji import text_has_emoji\n",
    "from src.nlp.patterns.brand_matcher import BRAND_PATTERNS\n",
    "from src.nlp.patterns.hook import HOOK_PATTERNS\n",
    "from src.nlp.patterns.direct_questions import DIRECT_QUESTION_PATTERNS\n",
    "from src.nlp.patterns.integration import INTEGRATION_PATTERNS, IntegrationPattern\n",
    "from src.nlp.patterns.curiosity import CURIOSITY_PATTERNS\n",
    "\n",
    "from src.nlp.text_utils.similarity import compare_first_and_last_sentence\n",
    "from src.cv.video.helpers import scene_num, get_video_duration\n",
    "from src.audio.analyze import energetic_music\n",
    "from src.nlp.text_utils.general_utils import second_person\n",
    "from src.ts.parser import extract_seconds_from_timestamps\n",
    "from scenedetect import detect, AdaptiveDetector\n",
    "\n",
    "from app.xgboost_service import XGBoostService\n",
    "from app.xgboost_adapter import XGBoostAdapter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load the data\n",
    "\n",
    "with open(\"output/transcription/wav_file_text_mapping.json\", \"rb\") as f: \n",
    "    audio_text = json.load(f)\n",
    "\n",
    "with open(\"output/dataset_info/influencer_data_set_info.json\", \"rb\") as f: \n",
    "    influencer_data = json.load(f)\n",
    "\n",
    "##### Load raw audios and get their keys\n",
    "with open(\"output/transcription/transcription_results.json\", \"rb\") as f: \n",
    "    raw_audios = json.load(f)\n",
    "\n",
    "audio_keys = list(raw_audios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(audio_text, index=[0]).T.reset_index()\n",
    "df.columns = ['path', 'transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "HOOK_THRESHOLD = 6\n",
    "KEYWORD_SPONSOR = \"sponsor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Does the introduction of the brand align with the wider video narrative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results/coterie/C-5_QPIyNVK_2024-08-20_21-17-5...</td>\n",
       "      <td>I just woke my baby up from a four hour nap. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results/coterie/C-DXZgbOkpL_2024-07-30_15-54-2...</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>results/coterie/C-ENTmNu4LL_2024-07-30_23-47-3...</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results/coterie/C-Nbj5Ss_kr_2024-08-03_13-43-1...</td>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results/coterie/C-V6tW3u8fR_2024-08-06_20-54-4...</td>\n",
       "      <td>Hey! Hey! Hey! Hey! Hey!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>results/theninjamas/DBZadHsPgLS_2024-10-21_19-...</td>\n",
       "      <td>See how I do my night time routine? Once I pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>results/theninjamas/DBZcfWGSbJo_2024-10-21_19-...</td>\n",
       "      <td>Nighttime routines can be chaotic, but thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>results/theninjamas/DBZyJxJSi7B_2024-10-21_22-...</td>\n",
       "      <td>Between home renovations during the day and n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>results/theninjamas/DBaWN8rp6tg_2024-10-22_03-...</td>\n",
       "      <td>These are our top potty training tips partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>results/theninjamas/DBbszl6RGAG_2024-10-22_16-...</td>\n",
       "      <td>When you're a four-year-old, the world is all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "0    results/coterie/C-5_QPIyNVK_2024-08-20_21-17-5...   \n",
       "1    results/coterie/C-DXZgbOkpL_2024-07-30_15-54-2...   \n",
       "2    results/coterie/C-ENTmNu4LL_2024-07-30_23-47-3...   \n",
       "3    results/coterie/C-Nbj5Ss_kr_2024-08-03_13-43-1...   \n",
       "4    results/coterie/C-V6tW3u8fR_2024-08-06_20-54-4...   \n",
       "..                                                 ...   \n",
       "387  results/theninjamas/DBZadHsPgLS_2024-10-21_19-...   \n",
       "388  results/theninjamas/DBZcfWGSbJo_2024-10-21_19-...   \n",
       "389  results/theninjamas/DBZyJxJSi7B_2024-10-21_22-...   \n",
       "390  results/theninjamas/DBaWN8rp6tg_2024-10-22_03-...   \n",
       "391  results/theninjamas/DBbszl6RGAG_2024-10-22_16-...   \n",
       "\n",
       "                                         transcription  \n",
       "0     I just woke my baby up from a four hour nap. ...  \n",
       "1                                           Thank you.  \n",
       "2                                           Thank you.  \n",
       "3                                Thank you. Thank you.  \n",
       "4                             Hey! Hey! Hey! Hey! Hey!  \n",
       "..                                                 ...  \n",
       "387   See how I do my night time routine? Once I pi...  \n",
       "388   Nighttime routines can be chaotic, but thanks...  \n",
       "389   Between home renovations during the day and n...  \n",
       "390   These are our top potty training tips partner...  \n",
       "391   When you're a four-year-old, the world is all...  \n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Brand introduced as the sponsor of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ALL_BRAND_MATCHING_PHRASES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m KEYWORD_SPONSOR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msponsor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m brand_patterns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mALL_BRAND_MATCHING_PHRASES\u001b[49m)\n\u001b[1;32m      4\u001b[0m transcription_ts \u001b[38;5;241m=\u001b[39m [[(raw_audios[audio][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m][ts][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], raw_audios[audio][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m][ts][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m], raw_audios[audio][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m][ts][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(raw_audios[audio][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m]))] \u001b[38;5;28;01mfor\u001b[39;00m audio \u001b[38;5;129;01min\u001b[39;00m audio_keys]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# We get tuples with the start and end ts where brand is matched\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ALL_BRAND_MATCHING_PHRASES' is not defined"
     ]
    }
   ],
   "source": [
    "brand_patterns = list(ALL_BRAND_MATCHING_PHRASES)\n",
    "\n",
    "transcription_ts = [[(raw_audios[audio][\"segments\"][ts][\"text\"], raw_audios[audio][\"segments\"][ts][\"start\"], raw_audios[audio][\"segments\"][ts][\"end\"]) for ts in range(len(raw_audios[audio][\"segments\"]))] for audio in audio_keys]\n",
    "\n",
    "# We get tuples with the start and end ts where brand is matched\n",
    "ts_brand = [[(transcription_ts[i][j][1], transcription_ts[i][j][2]) if findall_counter(transcription_ts[i][j][0], brand_patterns) else 0 for j in range(len(transcription_ts[i]))] for i in range(len(transcription_ts))]\n",
    "\n",
    "# Get the first tupple where the values are not 0\n",
    "first_brand_appearance = [next((x for x in lst_values if x), 0) for lst_values in ts_brand]\n",
    "\n",
    "# Get the average (orientative value where the name of the brand is verbalized)\n",
    "avg_ts_brand_appearance = [round(float(np.mean(values)), 2) for values in first_brand_appearance]\n",
    "\n",
    "# Get the dataframe\n",
    "brand_ts_df = pd.DataFrame({\"path\": audio_keys, \"BRAND_TS\": avg_ts_brand_appearance})\n",
    "\n",
    "# Get the path\n",
    "brand_ts_df[\"path\"] = brand_ts_df[\"path\"].apply(lambda x: x.split(\".wav\")[0])\n",
    "\n",
    "\n",
    "# Brand as sponsor in integration phase\n",
    "first_brand_appearance_start = [next((x[0] for x in lst_values if x), 0) for lst_values in ts_brand]\n",
    "\n",
    "texts_with_brand_start = [[transcription_ts[i][j] if (transcription_ts[i][j][1] == first_brand_appearance_start[i]) and (first_brand_appearance_start[i] != 0) else \"\" for j in range(len(transcription_ts[i]))] for i in range(len(transcription_ts))]\n",
    "texts_with_brand_start = [[tpl for tpl in segments if tpl != ''] for segments in texts_with_brand_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4: Background analysis -> Integration filmed in the same setting as the wider video and previous scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - 6 / 163 - 164: Duration of ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Video and Image paths\n",
    "\n",
    "\n",
    "video_paths = [video for sublist in influencer_data.values() for video in sublist[\"videos\"]]\n",
    "image_paths = [video for sublist in influencer_data.values() for video in sublist[\"images\"]]\n",
    "\n",
    "##### Video duration\n",
    "video_durations = [get_video_duration(video) for video in video_paths]\n",
    "\n",
    "video_df = pd.DataFrame({\"path\":video_paths, \"video_duration\": video_durations})\n",
    "\n",
    "\n",
    "\n",
    "# 163 and 164\n",
    "video_df[\"less_than_30_seconds\"] = video_df[\"video_durations\"].apply(lambda x: 1 if x <= 30 else 0)\n",
    "\n",
    "\n",
    "# Normalize path\n",
    "\n",
    "df[\"path\"] = df[\"path\"].apply(lambda x: x.split(\".wav\")[0])\n",
    "video_df[\"path\"] = video_df[\"path\"].apply(lambda x: x.split(\".mp4\")[0])\n",
    "\n",
    "df = df.merge(video_df, on=\"path\", how=\"left\")\n",
    "\n",
    "df[\"video_duration\"] = df[\"video_duration\"].fillna(0)\n",
    "\n",
    "# df.to_csv(\"saved_data/initial_df_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad length less than 6 seconds\n",
    "df[\"less_than_6_seconds\"] = df[\"video_duration\"].apply(lambda x: 1 if x <= 6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad length between 15 and 20 seconds\n",
    "df[\"between_15_and_20_seconds\"] = df[\"video_duration\"].apply(lambda x: 1 if x > 15 and x < 20 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7: Audience in central position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8: Brand logo shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTA: 9-15 (missing visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription_df\n",
    "transcription_df = detect_patterns(df = df, patterns = CTA_PATTERNS, column=\"transcription\")\n",
    "transcription_df.rename(\n",
    "    columns=lambda col: col + \"_transcription\" if col.startswith(\"CTA\") else col,\n",
    "    inplace=True\n",
    ")\n",
    "# Visual\n",
    "\n",
    "# ocr_df.rename(\n",
    "#     columns=lambda col: col + \"_ocr\" if col.startswith(\"CTA\") else col,\n",
    "#     inplace=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>transcription</th>\n",
       "      <th>CTA_BUY</th>\n",
       "      <th>CTA_GIFT</th>\n",
       "      <th>CTA_READ</th>\n",
       "      <th>CTA_SIGN_UP</th>\n",
       "      <th>CTA_FIND_OUT</th>\n",
       "      <th>CTA_LEARN</th>\n",
       "      <th>CTA_SUBSCRIBE</th>\n",
       "      <th>CTA_SHARE</th>\n",
       "      <th>CTA_DOWNLOAD</th>\n",
       "      <th>CTA_VISIT</th>\n",
       "      <th>CTA_CONTACT</th>\n",
       "      <th>CTA_PARTICIPATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results/coterie/C-5_QPIyNVK_2024-08-20_21-17-5...</td>\n",
       "      <td>I just woke my baby up from a four hour nap. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results/coterie/C-DXZgbOkpL_2024-07-30_15-54-2...</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>results/coterie/C-ENTmNu4LL_2024-07-30_23-47-3...</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results/coterie/C-Nbj5Ss_kr_2024-08-03_13-43-1...</td>\n",
       "      <td>Thank you. Thank you.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results/coterie/C-V6tW3u8fR_2024-08-06_20-54-4...</td>\n",
       "      <td>Hey! Hey! Hey! Hey! Hey!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>results/theninjamas/DBZadHsPgLS_2024-10-21_19-...</td>\n",
       "      <td>See how I do my night time routine? Once I pi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>results/theninjamas/DBZcfWGSbJo_2024-10-21_19-...</td>\n",
       "      <td>Nighttime routines can be chaotic, but thanks...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>results/theninjamas/DBZyJxJSi7B_2024-10-21_22-...</td>\n",
       "      <td>Between home renovations during the day and n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>results/theninjamas/DBaWN8rp6tg_2024-10-22_03-...</td>\n",
       "      <td>These are our top potty training tips partner...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>results/theninjamas/DBbszl6RGAG_2024-10-22_16-...</td>\n",
       "      <td>When you're a four-year-old, the world is all...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "0    results/coterie/C-5_QPIyNVK_2024-08-20_21-17-5...   \n",
       "1    results/coterie/C-DXZgbOkpL_2024-07-30_15-54-2...   \n",
       "2    results/coterie/C-ENTmNu4LL_2024-07-30_23-47-3...   \n",
       "3    results/coterie/C-Nbj5Ss_kr_2024-08-03_13-43-1...   \n",
       "4    results/coterie/C-V6tW3u8fR_2024-08-06_20-54-4...   \n",
       "..                                                 ...   \n",
       "387  results/theninjamas/DBZadHsPgLS_2024-10-21_19-...   \n",
       "388  results/theninjamas/DBZcfWGSbJo_2024-10-21_19-...   \n",
       "389  results/theninjamas/DBZyJxJSi7B_2024-10-21_22-...   \n",
       "390  results/theninjamas/DBaWN8rp6tg_2024-10-22_03-...   \n",
       "391  results/theninjamas/DBbszl6RGAG_2024-10-22_16-...   \n",
       "\n",
       "                                         transcription  CTA_BUY  CTA_GIFT  \\\n",
       "0     I just woke my baby up from a four hour nap. ...    False     False   \n",
       "1                                           Thank you.    False     False   \n",
       "2                                           Thank you.    False     False   \n",
       "3                                Thank you. Thank you.    False     False   \n",
       "4                             Hey! Hey! Hey! Hey! Hey!    False     False   \n",
       "..                                                 ...      ...       ...   \n",
       "387   See how I do my night time routine? Once I pi...    False     False   \n",
       "388   Nighttime routines can be chaotic, but thanks...    False     False   \n",
       "389   Between home renovations during the day and n...    False     False   \n",
       "390   These are our top potty training tips partner...    False     False   \n",
       "391   When you're a four-year-old, the world is all...    False     False   \n",
       "\n",
       "     CTA_READ  CTA_SIGN_UP  CTA_FIND_OUT  CTA_LEARN  CTA_SUBSCRIBE  CTA_SHARE  \\\n",
       "0       False        False         False      False          False      False   \n",
       "1       False        False         False      False          False      False   \n",
       "2       False        False         False      False          False      False   \n",
       "3       False        False         False      False          False      False   \n",
       "4       False        False         False      False          False      False   \n",
       "..        ...          ...           ...        ...            ...        ...   \n",
       "387     False        False         False      False          False      False   \n",
       "388     False        False         False      False          False      False   \n",
       "389     False        False         False      False          False      False   \n",
       "390     False        False         False      False          False      False   \n",
       "391     False        False         False      False          False      False   \n",
       "\n",
       "     CTA_DOWNLOAD  CTA_VISIT  CTA_CONTACT  CTA_PARTICIPATE  \n",
       "0           False      False        False            False  \n",
       "1           False      False        False            False  \n",
       "2           False      False        False            False  \n",
       "3           False      False        False            False  \n",
       "4           False      False        False            False  \n",
       "..            ...        ...          ...              ...  \n",
       "387         False      False        False            False  \n",
       "388         False      False        False            False  \n",
       "389         False      False        False            False  \n",
       "390         False      False        False            False  \n",
       "391         False      False        False            False  \n",
       "\n",
       "[392 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On visual\n",
    "# cta_columns = [col for col in ocr_df.columns if \"cta\" in col]\n",
    "# ocr_df[\"CTA_STICKER\"] = ocr_df[cta_columns].any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 Single call to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ocr_df.merge(transcription_df, how=\"left\", on=\"path\")\n",
    "\n",
    "cta_columns = [col for col in df.columns if \"CTA\" in col and col != \"CTA_STICKER\"]\n",
    "df[\"CTA_SINGLE\"] = df[cta_columns].sum(axis=1) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17 / 80: First and last sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transcription_ts = [[(raw_audios[audio][\"segments\"][ts][\"text\"], raw_audios[audio][\"segments\"][ts][\"start\"], raw_audios[audio][\"segments\"][ts][\"end\"]) for ts in range(len(raw_audios[audio][\"segments\"]))] for audio in audio_keys]\n",
    "\n",
    "# first_sentence = [[raw_audios[audio_key][\"segments\"][0][\"text\"]] for audio_key in audio_keys]\n",
    "# last_sentence = [[raw_audios[audio_key][\"segments\"][-1][\"text\"]] for audio_key in audio_keys]\n",
    "\n",
    "# first_sentence_set = [\n",
    "#     set(' '.join(text).replace('.', '').replace(',', '').replace(\"'\", \"\").lower().split())\n",
    "#     for text in first_sentence\n",
    "# ]\n",
    "\n",
    "# last_sentence_set = [\n",
    "#     set(' '.join(text).replace('.', '').replace(',', '').replace(\"'\", \"\").lower().split())\n",
    "#     for text in last_sentence\n",
    "# ]\n",
    "\n",
    "\n",
    "# def text_similarity(set_1, set_2): # Subject to change\n",
    "#     return 1 if set_1 == set_2 else 0\n",
    "\n",
    "# starts_ends_same_sentence = [text_similarity(first_sentence_set[i], last_sentence_set[i]) for i in range(len(first_sentence_set))]\n",
    "\n",
    "\n",
    "# Apply this to the text\n",
    "SIMILARITY_THRESHOLD = 0.5\n",
    "\n",
    "df[\"same_sentence\"] = df[\"transcription\"].apply(lambda x: compare_first_and_last_sentence(x, SIMILARITY_THRESHOLD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 - 42 / 47 - 57 / 59 - 61 / 66 - 68: Content Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription\n",
    "\n",
    "df = detect_patterns(df = df, patterns = POINT_OF_VIEW_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = UNBOXING_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = GRWM_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = RESTOCKING_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = DAY_IN_MY_LIFE_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = DUPE_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = HACK_PATTERNS, column=\"transcription\")\n",
    "df = detect_patterns(df = df, patterns = BTS_PATTERNS, column=\"transcription\") # Also 59-61\n",
    "df = detect_patterns(df = df, patterns = TIPS_PATTERNS, column=\"transcription\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr\n",
    "\n",
    "df = detect_patterns(df = df, patterns = POINT_OF_VIEW_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = UNBOXING_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = GRWM_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = RESTOCKING_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = DAY_IN_MY_LIFE_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = DUPE_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = HACK_PATTERNS, column=\"ocr\")\n",
    "df = detect_patterns(df = df, patterns = BTS_PATTERNS, column=\"ocr\") # Also 59-61\n",
    "df = detect_patterns(df = df, patterns = TIPS_PATTERNS, column=\"ocr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43 - 46 / 62 - 65: Surprise elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58: Close-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69: Ad or #Ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['hashtag_ad_count', 'standalone_ad_count']] = pd.DataFrame(\n",
    "    df['text'].apply(lambda x: count_two_words(x, \"ad\", \"#ad\")).tolist(), index=df.index\n",
    ")\n",
    "\n",
    "df['most_common'] = df.apply(\n",
    "    lambda row: 'hashtag_ad' if row['hashtag_ad_count'] > row['standalone_ad_count'] else \n",
    "                'standalone_ad' if row['standalone_ad_count'] > row['hashtag_ad_count'] else\n",
    "                'equal',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"paid_partnership\"] = df.apply(paid_partnership, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70: Broad range of brand elements used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "71 - 74: Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_emoji\"] = df[\"text\"].apply(text_has_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75: Format align with the top performing format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76 - 79: Hook \n",
    "\n",
    "132: Negative hook: Loss aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General and negative hook\n",
    "\n",
    "### This may need to be reworked since some of the 1st segments are much longer than 3 seconds\n",
    "\n",
    "\n",
    "end_first_segment = [raw_audios[audio_keys[i]][\"segments\"][0][\"end\"] for i in range(len(audio_keys))]\n",
    "text_first_segment = [raw_audios[audio_keys[i]][\"segments\"][0][\"text\"] for i in range(len(audio_keys))]\n",
    "\n",
    "##### Hook first 3 seconds\n",
    "\n",
    "hook_df = pd.DataFrame({\"path\": audio_keys, \"text\": text_first_segment, \"end_first_segment\": end_first_segment})\n",
    "\n",
    "tmp_df = hook_df[hook_df[\"end_first_segment\"] < HOOK_THRESHOLD]\n",
    "tmp_df = detect_patterns(df = tmp_df, patterns = HOOK_PATTERNS)\n",
    "\n",
    "hook_df = hook_df.fillna(False)\n",
    "\n",
    "# Brand introduced\n",
    "hook_df = detect_patterns(df = hook_df, patterns = BRAND_PATTERNS)\n",
    "# Rename all the brand patterns to end up with _HOOK\n",
    "\n",
    "# Trick, tip or hack\n",
    "hook_df = detect_patterns(df = hook_df, patterns = TIPS_PATTERNS, column=\"text\")\n",
    "\n",
    "# Elipsis\n",
    "hook_df[\"ELLIPSIS_HOOK\"] = hook_df[\"text\"].apply(lambda x: ellipsis(x))\n",
    "\n",
    "# Direct questions\n",
    "hook_df = detect_patterns(df = hook_df, patterns = DIRECT_QUESTION_PATTERNS)\n",
    "# Rename all the direct questions patterns to end up with _HOOK\n",
    "\n",
    "# Merge\n",
    "hook_df = hook_df.merge(tmp_df[[\"path\", \"GENERAL_HOOK\",\t\"NEGATIVE_HOOK\"]], on=\"path\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "# 132 -> Answered with the negative hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81: Text Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "82 -83: Creators being used -> Person detection / Associated with a specific category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84: More than one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "85: Creator shown in the first 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86 - 88: Scene changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_num_scenes = [scene_num(video) for video in video_paths]\n",
    "img_num_scenes = [1 for i in len(range(image_paths))]\n",
    "\n",
    "more_than_1_scene = [1 if video_scenes > 1 else 0 for video_scenes in video_num_scenes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "89: Brand revealed after 6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_second_segment = [raw_audios[audio_keys[i]][\"segments\"][1][\"start\"] if\n",
    "                    len(raw_audios[audio_keys[i]][\"segments\"]) > 1 else 0\n",
    "                    for i in range(len(audio_keys))]\n",
    "\n",
    "text_first_segment = [raw_audios[audio_keys[i]][\"segments\"][0][\"text\"] if \n",
    "                    len(raw_audios[audio_keys[i]][\"segments\"]) > 1 else \"\" \n",
    "                    for i in range(len(audio_keys))]\n",
    "\n",
    "texts = [raw_audios[audio_keys[i]][\"text\"] for i in range(len(audio_keys))]\n",
    "\n",
    "# Subtract\n",
    "text_for_brand_after_6 = [texts[i].replace(text_first_segment[i], \"\") for i in range(len(texts))]\n",
    "\n",
    "# If second segment starts after 6 \n",
    "text_for_brand_after_6 = [text_for_brand_after_6[i] if start_second_segment[i] > 6 else \"\" for i in range(len(text_for_brand_after_6))]\n",
    "\n",
    "# Metion the brand\n",
    "brand_6_sec_df = pd.DataFrame({\"path\": audio_keys, \"text\": text_for_brand_after_6})\n",
    "brand_6_sec_df = detect_patterns(df = brand_6_sec_df, patterns = BRAND_PATTERNS)\n",
    "# Rename the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90: Brand being the protagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "91: Brand placed at top center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92: Opening seconds include speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_first_segment = [raw_audios[audio_keys[i]][\"segments\"][0][\"end\"] for i in range(len(audio_keys))]\n",
    "\n",
    "opening_include_speech = [1 if text_first_segment[i] != \"\" and end_first_segment[i] < 6 else 0\n",
    "                        for i in range(len(end_first_segment))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93: In the first 2 seconds do we have more than 10 words. Should be worked with ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lst = [round((len(text_first_segment[i].split(\" \"))/end_first_segment[i]) * 2) for i in range(len(end_first_segment))]\n",
    "more_than_10_words = [1 if tmp_lst[i] >= 10 else 0 for i in range(len(tmp_lst))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94: Energetic music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"energetic_music\"] = df[\"bpm_values\"].apply(energetic_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95: Music in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96: Speaking directly to the audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speaking_directly_to_the_audience\"] = df[\"text\"].apply(second_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97: Asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = detect_patterns(df = df, patterns = DIRECT_QUESTION_PATTERNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98: Logo shown tied to the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99: Emotion sparking in the first 5 seconds -> Emotion Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100: Brand associated with the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "101: Framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "102 - 103: Smiling and recognizable faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "104 - 107: Image quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "108 - 109: Lo-fi / UGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "110 - 121 / 125 - 130: Composition, quality and lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "122 - 124: Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration after the first 10 seconds\n",
    "texts_with_brand_start = [[transcription_ts[i][j] if (transcription_ts[i][j][1] == first_brand_appearance_start[i]) and (first_brand_appearance_start[i] != 0) else \"\" for j in range(len(transcription_ts[i]))] for i in range(len(transcription_ts))]\n",
    "texts_with_brand_start = [[tpl for tpl in segments if tpl != ''] for segments in texts_with_brand_start]\n",
    "integration_after_10_secs = [1 if (avg_ts_brand_appearance[i] >= 10) and (avg_ts_brand_appearance[i] > 0) else 0 for i in range(len(avg_ts_brand_appearance))]\n",
    "\n",
    "# Integration in the first half of the video\n",
    "int_first_half_video = [1 if (avg_ts_brand_appearance[i] / video_durations[i] <= 0.50) and (avg_ts_brand_appearance[i] > 0) else 0 for i in range(len(avg_ts_brand_appearance))]\n",
    "\n",
    "# Integration after 10 seconds and in the first half of the video\n",
    "int_first_half_and_after_10_seconds = [1 if (int_first_half_video[i] and integration_after_10_secs[i]) else 0\n",
    "    for i in range(len(int_first_half_video))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> \"back to...\" or \"thanks again to... for sponsoring the video\", \"click the link in the description box...\" \n",
    "integration_ending_patterns = INTEGRATION_PATTERNS[IntegrationPattern.INTEGRATION_END]\n",
    "\n",
    "# Find the last time integration vocabulary was mentioned\n",
    "int_last = [[(transcription_ts[i][j][1], transcription_ts[i][j][2]) if findall_counter(transcription_ts[i][j][0], integration_ending_patterns) else 0 for j in range(len(transcription_ts[i]))] for i in range(len(transcription_ts))]\n",
    "\n",
    "# Get the first tupple where the values are not 0\n",
    "last_end_int_appearance = [next((x for x in reversed(lst_values) if x), 0) for lst_values in int_last]\n",
    "\n",
    "# Filter to get the last value\n",
    "end_integration = [x[1] if x != 0 else 0 for x in last_end_int_appearance]\n",
    "\n",
    "# end_integration - first_brand_appearance_start\n",
    "integration_duration = [end_integration[i] - first_brand_appearance_start[i] if (end_integration[i] != 0) and (first_brand_appearance_start[i] != 0) and (end_integration[i] > first_brand_appearance_start[i]) else 0 for i in range(len(first_brand_appearance_start))]\n",
    "\n",
    "# Integration between 90 and 240 seconds\n",
    "int_between_90_240 = [1 if (integration_duration[i] >= 90) and (integration_duration[i] <= 240) else 0 for i in range(len(integration_duration))]\n",
    "\n",
    "# # Integration timestamps\n",
    "# integration_ts = [(first_brand_appearance_start[i], end_integration[i]) if (end_integration[i] != 0) and (first_brand_appearance_start[i] != 0) and (end_integration[i] > first_brand_appearance_start[i]) else 0 for i in range(len(first_brand_appearance_start))]\n",
    "\n",
    "# # Set as (0, 0) where we have 0\n",
    "# integration_ts = [(0, 0) if x == 0 else x for x in integration_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "131: Key message -> LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "133 - 140: Conveying the same message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 134: If call to action _transcription and _ocr true then true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 135, 136, 137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "140 - 145 -> Single focal point: attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "146 - 149: Main message delivered in the first 6 seconds (Using CTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({\"path\": audio_keys, \"text\": text_first_segment, \"end_first_segment\": end_first_segment})\n",
    "\n",
    "# drop columns based on end of the first segment\n",
    "tmp_df = tmp_df.drop(tmp_df[tmp_df[\"end_first_segment\"] > 3].index)\n",
    "tmp_df = detect_patterns(df = tmp_df, patterns = CTA_PATTERNS, column=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 - 153: Brand elements at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = detect_patterns(df = tmp_df, patterns = BRAND_PATTERNS, column=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "154 - 162 / 165 - 170: Size and dimensions and product visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "171 - 174: Product in usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "175: Product being used during the entire ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "176 - 183: Overlay and Captions (OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "184 - 187: Video understandable without sound (dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "188: Automated subtitles or closed caption -> Answered with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "189 - 207: Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Has voice based on the fact that transcriptions are are only made if we have voice in the audio -> 193 - 196\n",
    "\n",
    "video_df = pd.DataFrame({\"path\": video_paths})\n",
    "video_df[\"cleaned_path\"] = video_df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".mp4\")[0])\n",
    "tmp_lst = transcription_df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".wav\")[0])\n",
    "video_df[\"has_voice\"] = video_df[\"cleaned_path\"].isin(tmp_lst).astype(int)\n",
    "video_df[\"has_voice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound included -> 197 - 200\n",
    "sound_effects = [\"Static\", \"Engine\", \"Radio\"]\n",
    "\n",
    "def sound_effect(row, col_list):\n",
    "    total = sum(row[col] for col in col_list)\n",
    "    return 1 if total > 0.0 else 0\n",
    "\n",
    "# dynamic_creative_df['sound_effect_detected'] = dynamic_creative_df.apply(sound_effect, col_list=sound_effects, axis=1)\n",
    "\n",
    "\n",
    "# Sound effect and voice -> 189 - 192\n",
    "\n",
    "\n",
    "# Voice clearly heard in overlay to music -> 201 - 204\n",
    "\n",
    "\n",
    "# Include sound -> 205 \n",
    "\n",
    "\n",
    "# Brand mentioned audible -> 206 \n",
    "\n",
    "brand_mentioned_audible = [0 if ts_brand[i] == 0 else 1 for i in range(len(ts_brand))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTA paired with voice -> 207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "208 - 211 -> Story arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "212 - 215: Ellipsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_ellipsis\"] = df[\"text\"].apply(lambda x: ellipsis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "216 - 221: What's comming next and ask audience opinion to spike curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df = detect_patterns(df = transcription_df, patterns = CURIOSITY_PATTERNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "222: Establishing the problem to bring the product as the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "223: T&C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "224 - 227: 20% of the image occupied by text and text in lowercase. Plus, key message in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_df[\"lowercase_ocr\"] = [string.islower() for string in ocr_df[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "228 - 230: Overlay with contrasting visuals and font type sans serif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "231 - 232: 5 - 10 words per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "233: Multiple scene changes throught the integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scenes\n",
    "scenes_videos = [detect(video_paths[i], AdaptiveDetector()) for i in range(len(video_paths))]\n",
    "\n",
    "# Filter the timestamps\n",
    "scenes_ts = [[(scenes_videos[i][j][0].get_timecode(), scenes_videos[i][j][1].get_timecode()) for j in range(len(scenes_videos[i]))] for i in range(len(scenes_videos))]\n",
    "\n",
    "# Get posprocessed scenes\n",
    "postprocessed_scenes = [[extract_seconds_from_timestamps(scenes_ts[i][j]) for j in range(len(scenes_ts[i]))] for i in range(len(scenes_ts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "234 - 235: trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "236 - 237: Safe Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<app.xgboost_service.XGBoostService at 0x15e57c8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBoostService(xgboost_adapter=XGBoostAdapter)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
